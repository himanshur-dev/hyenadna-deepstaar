{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "495fff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.25.1)\n",
      "Requirement already satisfied: scipy in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.11.1)\n",
      "Requirement already satisfied: pandas in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: matplotlib in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.7.2)\n",
      "Requirement already satisfied: tqdm in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (4.65.0)\n",
      "Requirement already satisfied: rich in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (13.4.2)\n",
      "Requirement already satisfied: pytorch-lightning==1.8.6 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.8.6)\n",
      "Requirement already satisfied: hydra-core in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.3.2)\n",
      "Requirement already satisfied: omegaconf in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2.3.0)\n",
      "Requirement already satisfied: wandb in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.15.5)\n",
      "Requirement already satisfied: einops in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.6.1)\n",
      "Requirement already satisfied: opt_einsum in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (3.3.0)\n",
      "Requirement already satisfied: cmake in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (3.27.0)\n",
      "Requirement already satisfied: transformers in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (4.31.0)\n",
      "Requirement already satisfied: torchvision in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (0.14.0)\n",
      "Requirement already satisfied: timm in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (0.9.2)\n",
      "Requirement already satisfied: prettytable in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 19)) (3.8.0)\n",
      "Requirement already satisfied: numerize in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (0.12)\n",
      "Requirement already satisfied: torchtext==0.14.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 23)) (0.14.0)\n",
      "Requirement already satisfied: datasets in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 24)) (2.13.1)\n",
      "Requirement already satisfied: pyfaidx in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 27)) (0.7.2.1)\n",
      "Requirement already satisfied: polars in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (0.18.8)\n",
      "Requirement already satisfied: genomic-benchmarks in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 29)) (0.0.9)\n",
      "Requirement already satisfied: loguru in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 30)) (0.7.0)\n",
      "Requirement already satisfied: liftover in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 31)) (1.1.16)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from pytorch-lightning==1.8.6->-r requirements.txt (line 8)) (2023.6.0)\n",
      "Requirement already satisfied: torch>=1.9.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from pytorch-lightning==1.8.6->-r requirements.txt (line 8)) (1.13.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from pytorch-lightning==1.8.6->-r requirements.txt (line 8)) (4.7.1)\n",
      "Requirement already satisfied: tensorboardX>=2.2 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from pytorch-lightning==1.8.6->-r requirements.txt (line 8)) (2.6.1)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from pytorch-lightning==1.8.6->-r requirements.txt (line 8)) (1.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from pytorch-lightning==1.8.6->-r requirements.txt (line 8)) (6.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from pytorch-lightning==1.8.6->-r requirements.txt (line 8)) (23.0)\n",
      "Requirement already satisfied: lightning-utilities!=0.4.0,>=0.3.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from pytorch-lightning==1.8.6->-r requirements.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: requests in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from torchtext==0.14.0->-r requirements.txt (line 23)) (2.28.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 3)) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (9.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (4.41.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from rich->-r requirements.txt (line 7)) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from rich->-r requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from hydra-core->-r requirements.txt (line 9)) (4.9.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 11)) (5.9.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: pathtools in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 11)) (0.1.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 11)) (8.0.4)\n",
      "Requirement already satisfied: setuptools in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 11)) (65.6.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 11)) (4.23.4)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 11)) (3.1.32)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 11)) (1.4.4)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 11)) (1.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 16)) (0.13.3)\n",
      "Requirement already satisfied: filelock in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 16)) (3.9.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 16)) (0.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 16)) (0.16.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 16)) (2023.6.3)\n",
      "Requirement already satisfied: wcwidth in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from prettytable->-r requirements.txt (line 19)) (0.2.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 24)) (12.0.1)\n",
      "Requirement already satisfied: xxhash in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 24)) (3.2.0)\n",
      "Requirement already satisfied: aiohttp in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 24)) (3.8.5)\n",
      "Requirement already satisfied: multiprocess in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 24)) (0.70.14)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 24)) (0.3.6)\n",
      "Requirement already satisfied: six in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from pyfaidx->-r requirements.txt (line 27)) (1.16.0)\n",
      "Requirement already satisfied: pip>=20.0.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from genomic-benchmarks->-r requirements.txt (line 29)) (22.3.1)\n",
      "Requirement already satisfied: biopython>=1.79 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from genomic-benchmarks->-r requirements.txt (line 29)) (1.81)\n",
      "Requirement already satisfied: yarl in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from genomic-benchmarks->-r requirements.txt (line 29)) (1.9.2)\n",
      "Requirement already satisfied: gdown>=4.2.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from genomic-benchmarks->-r requirements.txt (line 29)) (4.7.1)\n",
      "Requirement already satisfied: urllib3 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from liftover->-r requirements.txt (line 31)) (1.26.15)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 24)) (1.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 24)) (2.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 24)) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 24)) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 24)) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 24)) (22.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from gdown>=4.2.0->genomic-benchmarks->-r requirements.txt (line 29)) (4.12.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 11)) (4.0.10)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 7)) (0.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from requests->torchtext==0.14.0->-r requirements.txt (line 23)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from requests->torchtext==0.14.0->-r requirements.txt (line 23)) (2023.5.7)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 11)) (5.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.2.0->genomic-benchmarks->-r requirements.txt (line 29)) (2.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from requests->torchtext==0.14.0->-r requirements.txt (line 23)) (1.7.1)\n",
      "Requirement already satisfied: lightning in /Users/himanshu/anaconda3/lib/python3.10/site-packages (2.0.5)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (6.0)\n",
      "Requirement already satisfied: starsessions<2.0,>=1.2.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (1.3.0)\n",
      "Requirement already satisfied: Jinja2<5.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (3.1.2)\n",
      "Requirement already satisfied: websocket-client<3.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (1.5.1)\n",
      "Requirement already satisfied: inquirer<5.0,>=2.10.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (3.1.3)\n",
      "Requirement already satisfied: arrow<3.0,>=1.2.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (1.2.3)\n",
      "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (2023.6.0)\n",
      "Requirement already satisfied: torch<4.0,>=1.11.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (1.13.0)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (4.65.0)\n",
      "Requirement already satisfied: fastapi<2.0,>=0.92.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (0.100.0)\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (4.12.2)\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.7.4 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (1.10.11)\n",
      "Requirement already satisfied: packaging<25.0,>=17.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (23.0)\n",
      "Requirement already satisfied: deepdiff<8.0,>=5.7.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (6.3.1)\n",
      "Requirement already satisfied: croniter<1.5.0,>=1.3.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (1.4.1)\n",
      "Requirement already satisfied: urllib3<4.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (1.26.15)\n",
      "Requirement already satisfied: websockets<13.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (11.0.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (1.25.1)\n",
      "Requirement already satisfied: starlette in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (0.27.0)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (4.7.1)\n",
      "Requirement already satisfied: dateutils<2.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (0.6.12)\n",
      "Requirement already satisfied: psutil<7.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (5.9.4)\n",
      "Requirement already satisfied: rich<15.0,>=12.3.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (13.4.2)\n",
      "Requirement already satisfied: backoff<4.0,>=2.2.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (2.2.1)\n",
      "Requirement already satisfied: lightning-cloud>=0.5.37 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (0.5.37)\n",
      "Requirement already satisfied: torchmetrics<2.0,>=0.7.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (1.0.1)\n",
      "Requirement already satisfied: click<10.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (8.0.4)\n",
      "Requirement already satisfied: requests<4.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (2.28.1)\n",
      "Requirement already satisfied: uvicorn<2.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (0.23.1)\n",
      "Requirement already satisfied: python-multipart<2.0,>=0.0.5 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (0.0.6)\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (5.9.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (0.9.0)\n",
      "Requirement already satisfied: pytorch-lightning in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning) (1.8.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.4)\n",
      "Requirement already satisfied: pytz in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from dateutils<2.0->lightning) (2022.7)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from deepdiff<8.0,>=5.7.0->lightning) (4.1.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.5)\n",
      "Requirement already satisfied: readchar>=3.0.6 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (4.0.5)\n",
      "Requirement already satisfied: blessed>=1.19.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.20.0)\n",
      "Requirement already satisfied: python-editor>=1.0.4 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from Jinja2<5.0->lightning) (2.1.2)\n",
      "Requirement already satisfied: pyjwt in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning-cloud>=0.5.37->lightning) (2.4.0)\n",
      "Requirement already satisfied: six in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from lightning-cloud>=0.5.37->lightning) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from requests<4.0->lightning) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from requests<4.0->lightning) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from requests<4.0->lightning) (2.0.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from starlette->lightning) (3.6.2)\n",
      "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from uvicorn<2.0->lightning) (0.14.0)\n",
      "Requirement already satisfied: tensorboardX>=2.2 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from pytorch-lightning->lightning) (2.6.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.3.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning) (0.1.2)\n",
      "Requirement already satisfied: setuptools>=41.0 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (65.6.3)\n",
      "Requirement already satisfied: protobuf>=4.22.3 in /Users/himanshu/anaconda3/lib/python3.10/site-packages (from tensorboardX>=2.2->pytorch-lightning->lightning) (4.23.4)\n"
     ]
    }
   ],
   "source": [
    "# To install the needed packages, uncomment the following two lines:\n",
    "!python3 -m pip install -r requirements.txt\n",
    "!python3 -m pip install lightning\n",
    "# NOTE: Be sure to also install git lfs! Installation instructions can be found here:\n",
    "# https://docs.github.com/en/repositories/working-with-files/managing-large-files/installing-git-large-file-storage?platform=mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8050bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the name of the pretrained model (see possible_pretrained_names below for options), use None if \n",
    "# training from scratch\n",
    "pretrained_model_name = \"hyenadna-tiny-1k-seqlen\" \n",
    "# path to your training data\n",
    "train_data_path = '/Users/himanshu/Desktop/hyenadna-deepstaar/deepstaar-data/filtered-data-train.csv' \n",
    "# path to your test data\n",
    "test_data_path = '/Users/himanshu/Desktop/hyenadna-deepstaar/deepstaar-data/filtered-data-test.csv' \n",
    "# number of labels (regression heads) you want to use\n",
    "num_labels = 3\n",
    "\n",
    "# the ratio of train data you want to include, where 0.0 is nothing and 1.0 is everything \n",
    "# can be made smaller to make testing faster\n",
    "train_data_subset_ratio = 1.0\n",
    "# the ratio of test data you want to include, where 0.0 is nothing and 1.0 is everything\n",
    "# can be made smaller to make testing faster\n",
    "test_data_subset_ratio = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9217c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks\n",
    "import os\n",
    "def is_valid_path(path):\n",
    "    return os.path.exists(path)\n",
    "possible_pretrained_names = ['hyenadna-tiny-1k-seqlen', \n",
    "                             'hyenadna-small-32k-seqlen', \n",
    "                             'hyenadna-medium-160k-seqlen', \n",
    "                             'hyenadna-medium-450k-seqlen', \n",
    "                             'hyenadna-large-1m-seqlen']\n",
    "\n",
    "assert pretrained_model_name == None or \\\n",
    "       pretrained_model_name in possible_pretrained_names\n",
    "assert is_valid_path(train_data_path)\n",
    "assert is_valid_path(test_data_path)\n",
    "for ratio in [train_data_subset_ratio, test_data_subset_ratio]:\n",
    "    assert ratio >= 0.0 and ratio <= 1.0\n",
    "assert num_labels > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a5dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import LightningModule\n",
    "import torch\n",
    "from transformers import DataCollatorWithPadding\n",
    "import wandb\n",
    "import evaluate\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from scipy.stats import pearsonr\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cffd20c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Updated Git hooks.\n",
      "Git LFS initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'hyenadna-small-32k-seqlen'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights ok!\n",
      "torch.Size([1, 32770, 256])\n"
     ]
    }
   ],
   "source": [
    "# these take a little longer so they are in a separate cell\n",
    "from huggingface import HyenaDNAPreTrainedModel\n",
    "from standalone_hyenadna import CharacterTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bb40bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDNADataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, num_labels, max_length=1000, use_padding=True):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_padding = use_padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sequence = self.data.iloc[idx, 0]\n",
    "        label_data = []\n",
    "        for i in range(num_labels):\n",
    "            label_data.append(self.data.iloc[idx, i+1])\n",
    "\n",
    "        # label1 = self.data.iloc[idx, 1]\n",
    "        # label2 = self.data.iloc[idx, 2]\n",
    "        # label3 = self.data.iloc[idx, 3]\n",
    "        \n",
    "        # tokenize sequence\n",
    "        tokenized_sequence = self.tokenizer(sequence, padding=self.use_padding, truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
    "        \n",
    "        sample = {'input_ids': tokenized_sequence['input_ids'][0]}\n",
    "        for i, label in enumerate(label_data):\n",
    "            sample[f'label{i+1}'] = torch.tensor(label)\n",
    "        # sample = {'input_ids': tokenized_sequence['input_ids'][0], 'label1': torch.tensor(label1), 'label2': torch.tensor(label2), 'label3': torch.tensor(label3)}\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3163316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader that only has 1/10th of the training data set\n",
    "def create_subset_loader(ds, batch_size, shuffle=False, subset_fraction=1.0):\n",
    "    torch.manual_seed(0)\n",
    "    subset_size = int(len(ds) * subset_fraction)\n",
    "    indices = list(range(len(ds)))\n",
    "    np.random.shuffle(indices)\n",
    "    subset_indices = indices[:subset_size]\n",
    "    ds_subset = Subset(ds, subset_indices)\n",
    "    train_loader = DataLoader(ds_subset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return train_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bffa3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, loss_fn, num_labels, log_interval=10):\n",
    "    \"\"\"Training loop.\"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        data = batch['input_ids'].to(device).long()\n",
    "        targets_arr = []\n",
    "        for i in range(num_labels):\n",
    "            targets_arr.append(batch[f'label{i+1}'].to(device).float())\n",
    "        # target1 = batch['label1'].to(device).float()\n",
    "        # target2 = batch['label2'].to(device).float()\n",
    "        # target3 = batch['label3'].to(device).float()\n",
    "        # print(\"data: \", data)\n",
    "        # print(\"target1: \", target1)\n",
    "        # print(\"target2: \", target2)\n",
    "        # print(\"target3: \", target3)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # print(\"output: \", output)\n",
    "        # print(\"output shape: \", output.shape)\n",
    "        targets = torch.stack([target for target in targets_arr], dim=1)\n",
    "        # print(\"targets: \", targets)\n",
    "        loss = loss_fn(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader, loss_fn, num_labels):\n",
    "    \"\"\"Test loop.\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            data = batch['input_ids'].to(device).long()\n",
    "            # target1 = batch['label1'].to(device).float()\n",
    "            # target2 = batch['label2'].to(device).float()\n",
    "            # target3 = batch['label3'].to(device).float()\n",
    "            targets_arr = []\n",
    "            for i in range(num_labels):\n",
    "                targets_arr.append(batch[f'label{i+1}'].to(device).float())\n",
    "            # targets = torch.stack((target1, target2, target3), dim=1)\n",
    "            targets = torch.stack([target for target in targets_arr], dim=1)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, targets).item()  # sum up batch loss\n",
    "            # collect all predictions and actual labels\n",
    "            all_preds.extend(output.squeeze().detach().cpu().numpy())\n",
    "            all_labels.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}'.format(test_loss))\n",
    "    \n",
    "    # calculate Pearson correlation coefficient\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    r_value, p_value = pearsonr(all_preds.flatten(), all_labels.flatten())\n",
    "    print('Pearson correlation coefficient: {:.4f}'.format(r_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21c878da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import transformers\n",
    "from transformers import PreTrainedModel, AutoModelForCausalLM, PretrainedConfig\n",
    "import torch.nn as nn\n",
    "\n",
    "def run_train(num_labels):\n",
    "    # experiment settings:\n",
    "    num_epochs = 100  # ~100 seems fine\n",
    "    batch_size = 256\n",
    "    learning_rate = 6e-4  # good default for Hyena\n",
    "    weight_decay = 0.1\n",
    "\n",
    "    # these are used for the regression head\n",
    "    use_head = True\n",
    "    n_classes = num_labels\n",
    "\n",
    "    # you can override with your own backbone config here if you want,\n",
    "    # otherwise we'll load the HF one by default\n",
    "    backbone_cfg = None\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # instantiate the model (pretrained here)\n",
    "    if pretrained_model_name in ['hyenadna-tiny-1k-seqlen', \n",
    "                                 'hyenadna-small-32k-seqlen', \n",
    "                                 'hyenadna-medium-160k-seqlen', \n",
    "                                 'hyenadna-medium-450k-seqlen', \n",
    "                                 'hyenadna-large-1m-seqlen']:\n",
    "        # use the pretrained Huggingface wrapper instead\n",
    "        model = HyenaDNAPreTrainedModel.from_pretrained(\n",
    "            './checkpoints',\n",
    "            pretrained_model_name,\n",
    "            download=True,\n",
    "            config=backbone_cfg,\n",
    "            device=device,\n",
    "            use_head=use_head,\n",
    "            n_classes=n_classes,\n",
    "        )\n",
    "\n",
    "    # from scratch\n",
    "    else:\n",
    "        model = HyenaDNAPreTrainedModel(**backbone_cfg, use_head=use_head, n_classes=n_classes)\n",
    "        \n",
    "    max_lengths = {\n",
    "        'hyenadna-tiny-1k-seqlen': 1024,\n",
    "        'hyenadna-small-32k-seqlen': 32768,\n",
    "        'hyenadna-medium-160k-seqlen': 160000,\n",
    "        'hyenadna-medium-450k-seqlen': 450000,  \n",
    "        'hyenadna-large-1m-seqlen': 1_000_000,\n",
    "    }\n",
    "\n",
    "    # create tokenizer\n",
    "    tokenizer = CharacterTokenizer(\n",
    "        characters=['A', 'C', 'G', 'T', 'N'],  # add DNA characters, N is uncertain\n",
    "        model_max_length=max_lengths[pretrained_model_name], \n",
    "        add_special_tokens=False,  # we handle special tokens elsewhere\n",
    "        padding_side='left', # since HyenaDNA is causal, we pad on the left\n",
    "    )\n",
    "\n",
    "    ds_train = CustomDNADataset(train_data_path, tokenizer, max_lengths[pretrained_model_name])\n",
    "    ds_test = CustomDNADataset(test_data_path, tokenizer, max_lengths[pretrained_model_name])\n",
    "    \n",
    "    train_loader = create_subset_loader(ds_train, batch_size, shuffle=True, subset_fraction=train_data_subset_ratio)\n",
    "    test_loader = create_subset_loader(ds_test, batch_size=batch_size, shuffle=False, subset_fraction=test_data_subset_ratio)\n",
    "\n",
    "    # print(\"train loader: \", ds_train.data)\n",
    "    # print(\"test loader: \", ds_test.data)\n",
    "\n",
    "    # loss function\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    # create optimizer\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train(model, device, train_loader, optimizer, epoch, loss_fn, num_labels)\n",
    "        test(model, device, test_loader, loss_fn, num_labels)\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5411df36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Updated Git hooks.\n",
      "Git LFS initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'hyenadna-tiny-1k-seqlen'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights ok!\n",
      "train loader:                                                  text    label1    label2  \\\n",
      "0  ATTCAGATTGCCTCTCATTGTCTCACCCATATTATGGGAACCAAAT...  1.213124  2.334324   \n",
      "1  AAATGGCCGCTCAAGAAAAGGCTCGAATATATATTGCCTGCCTCTC...  1.213124  2.334324   \n",
      "2  ATAAGGATCAAAAAGTCCTGATTTCCGAAATGGCGGTTCTCCTTCA...  1.213124  2.334324   \n",
      "3  TTTCCATGACTGACTGGAATGGGTGGAGAACATCGCTTTGGGAGTG...  1.213124  2.334324   \n",
      "4  TCTATCGACCCATAGCCGTAGTCGCTAGACCCGCCCTTCGGAGCAT...  1.213124  2.334324   \n",
      "5  ACTCTGTTCAAGTTGTTGTTTTTGTTGTTGATGGTTTGTGAGAGTA...  1.213124  2.334324   \n",
      "6  TCTCTGTAGTTGAACTTGAACCGATGCTCCAAGCTTGGATGGTAAA...  1.213124  2.334324   \n",
      "7  TTAAGCTTTTGAAAGTAAGAGTAAAGTTAACGCTTGCGCCATTGCA...  1.213124  2.334324   \n",
      "8  CGGCGGTGCAAACAACGTAGGAGAGGCGAGAGCAAAGAAAGAGTAC...  1.213124  2.334324   \n",
      "\n",
      "     label3  \n",
      "0  12.21321  \n",
      "1  12.21321  \n",
      "2  12.21321  \n",
      "3  12.21321  \n",
      "4  12.21321  \n",
      "5  12.21321  \n",
      "6  12.21321  \n",
      "7  12.21321  \n",
      "8  12.21321  \n",
      "test loader:                                                  text    label1    label2  \\\n",
      "0  ATTCAGATTGCCTCTCATTGTCTCACCCATATTATGGGAACCAAAT...  1.213124  2.334324   \n",
      "1  AAATGGCCGCTCAAGAAAAGGCTCGAATATATATTGCCTGCCTCTC...  1.213124  2.334324   \n",
      "2  ATAAGGATCAAAAAGTCCTGATTTCCGAAATGGCGGTTCTCCTTCA...  1.213124  2.334324   \n",
      "3  TTTCCATGACTGACTGGAATGGGTGGAGAACATCGCTTTGGGAGTG...  1.213124  2.334324   \n",
      "4  TCTATCGACCCATAGCCGTAGTCGCTAGACCCGCCCTTCGGAGCAT...  1.213124  2.334324   \n",
      "5  ACTCTGTTCAAGTTGTTGTTTTTGTTGTTGATGGTTTGTGAGAGTA...  1.213124  2.334324   \n",
      "6  TCTCTGTAGTTGAACTTGAACCGATGCTCCAAGCTTGGATGGTAAA...  1.213124  2.334324   \n",
      "7  TTAAGCTTTTGAAAGTAAGAGTAAAGTTAACGCTTGCGCCATTGCA...  1.213124  2.334324   \n",
      "8  CGGCGGTGCAAACAACGTAGGAGAGGCGAGAGCAAAGAAAGAGTAC...  1.213124  2.334324   \n",
      "\n",
      "     label3  \n",
      "0  12.21321  \n",
      "1  12.21321  \n",
      "2  12.21321  \n",
      "3  12.21321  \n",
      "4  12.21321  \n",
      "5  12.21321  \n",
      "6  12.21321  \n",
      "7  12.21321  \n",
      "8  12.21321  \n",
      "getting last token\n",
      "Train Epoch: 0 [0/9 (0%)]\tLoss: 52.060230\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 5.7852\n",
      "Pearson correlation coefficient: -0.9837\n",
      "getting last token\n",
      "Train Epoch: 1 [0/9 (0%)]\tLoss: 52.049160\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 5.7431\n",
      "Pearson correlation coefficient: 0.8092\n",
      "getting last token\n",
      "Train Epoch: 2 [0/9 (0%)]\tLoss: 51.515244\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 5.7058\n",
      "Pearson correlation coefficient: 0.8337\n",
      "getting last token\n",
      "Train Epoch: 3 [0/9 (0%)]\tLoss: 51.183231\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 5.6638\n",
      "Pearson correlation coefficient: 0.8243\n",
      "getting last token\n",
      "Train Epoch: 4 [0/9 (0%)]\tLoss: 50.774685\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 5.6151\n",
      "Pearson correlation coefficient: 0.8427\n",
      "getting last token\n",
      "Train Epoch: 5 [0/9 (0%)]\tLoss: 50.398167\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 5.5601\n",
      "Pearson correlation coefficient: 0.8475\n",
      "getting last token\n",
      "Train Epoch: 6 [0/9 (0%)]\tLoss: 49.794487\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 5.5041\n",
      "Pearson correlation coefficient: 0.8488\n",
      "getting last token\n",
      "Train Epoch: 7 [0/9 (0%)]\tLoss: 50.363594\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 5.4250\n",
      "Pearson correlation coefficient: 0.8417\n",
      "getting last token\n",
      "Train Epoch: 8 [0/9 (0%)]\tLoss: 48.528080\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 5.3514\n",
      "Pearson correlation coefficient: 0.8302\n",
      "getting last token\n",
      "Train Epoch: 9 [0/9 (0%)]\tLoss: 47.759377\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 5.2575\n",
      "Pearson correlation coefficient: 0.8238\n",
      "getting last token\n",
      "Train Epoch: 10 [0/9 (0%)]\tLoss: 46.834274\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 5.1455\n",
      "Pearson correlation coefficient: 0.8237\n",
      "getting last token\n",
      "Train Epoch: 11 [0/9 (0%)]\tLoss: 45.749424\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 5.0176\n",
      "Pearson correlation coefficient: 0.8279\n",
      "getting last token\n",
      "Train Epoch: 12 [0/9 (0%)]\tLoss: 44.528290\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 4.8750\n",
      "Pearson correlation coefficient: 0.8338\n",
      "getting last token\n",
      "Train Epoch: 13 [0/9 (0%)]\tLoss: 43.184589\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 4.7189\n",
      "Pearson correlation coefficient: 0.8434\n",
      "getting last token\n",
      "Train Epoch: 14 [0/9 (0%)]\tLoss: 41.729073\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 4.5509\n",
      "Pearson correlation coefficient: 0.8621\n",
      "getting last token\n",
      "Train Epoch: 15 [0/9 (0%)]\tLoss: 40.170589\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 4.3715\n",
      "Pearson correlation coefficient: 0.8916\n",
      "getting last token\n",
      "Train Epoch: 16 [0/9 (0%)]\tLoss: 38.503593\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 4.1808\n",
      "Pearson correlation coefficient: 0.9314\n",
      "getting last token\n",
      "Train Epoch: 17 [0/9 (0%)]\tLoss: 36.736496\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 3.9798\n",
      "Pearson correlation coefficient: 0.9748\n",
      "getting last token\n",
      "Train Epoch: 18 [0/9 (0%)]\tLoss: 34.886997\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 3.7705\n",
      "Pearson correlation coefficient: 0.9995\n",
      "getting last token\n",
      "Train Epoch: 19 [0/9 (0%)]\tLoss: 32.969357\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 3.5534\n",
      "Pearson correlation coefficient: 0.9871\n",
      "getting last token\n",
      "Train Epoch: 20 [0/9 (0%)]\tLoss: 30.982971\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 3.3307\n",
      "Pearson correlation coefficient: 0.9518\n",
      "getting last token\n",
      "Train Epoch: 21 [0/9 (0%)]\tLoss: 28.959469\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 3.1028\n",
      "Pearson correlation coefficient: 0.9173\n",
      "getting last token\n",
      "Train Epoch: 22 [0/9 (0%)]\tLoss: 26.881237\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 2.8701\n",
      "Pearson correlation coefficient: 0.8940\n",
      "getting last token\n",
      "Train Epoch: 23 [0/9 (0%)]\tLoss: 24.795055\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 2.6361\n",
      "Pearson correlation coefficient: 0.8834\n",
      "getting last token\n",
      "Train Epoch: 24 [0/9 (0%)]\tLoss: 22.662222\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 2.4003\n",
      "Pearson correlation coefficient: 0.8835\n",
      "getting last token\n",
      "Train Epoch: 25 [0/9 (0%)]\tLoss: 20.543137\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 2.1654\n",
      "Pearson correlation coefficient: 0.8915\n",
      "getting last token\n",
      "Train Epoch: 26 [0/9 (0%)]\tLoss: 18.417355\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 1.9274\n",
      "Pearson correlation coefficient: 0.9041\n",
      "getting last token\n",
      "Train Epoch: 27 [0/9 (0%)]\tLoss: 16.290771\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 1.6930\n",
      "Pearson correlation coefficient: 0.9185\n",
      "getting last token\n",
      "Train Epoch: 28 [0/9 (0%)]\tLoss: 14.214613\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 1.4640\n",
      "Pearson correlation coefficient: 0.9330\n",
      "getting last token\n",
      "Train Epoch: 29 [0/9 (0%)]\tLoss: 12.183683\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 1.2465\n",
      "Pearson correlation coefficient: 0.9467\n",
      "getting last token\n",
      "Train Epoch: 30 [0/9 (0%)]\tLoss: 10.267167\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 1.0377\n",
      "Pearson correlation coefficient: 0.9593\n",
      "getting last token\n",
      "Train Epoch: 31 [0/9 (0%)]\tLoss: 8.423524\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.8396\n",
      "Pearson correlation coefficient: 0.9707\n",
      "getting last token\n",
      "Train Epoch: 32 [0/9 (0%)]\tLoss: 6.739743\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.6619\n",
      "Pearson correlation coefficient: 0.9806\n",
      "getting last token\n",
      "Train Epoch: 33 [0/9 (0%)]\tLoss: 5.229889\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.5012\n",
      "Pearson correlation coefficient: 0.9887\n",
      "getting last token\n",
      "Train Epoch: 34 [0/9 (0%)]\tLoss: 3.857812\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.3629\n",
      "Pearson correlation coefficient: 0.9945\n",
      "getting last token\n",
      "Train Epoch: 35 [0/9 (0%)]\tLoss: 2.731545\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.2505\n",
      "Pearson correlation coefficient: 0.9981\n",
      "getting last token\n",
      "Train Epoch: 36 [0/9 (0%)]\tLoss: 1.821424\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.1606\n",
      "Pearson correlation coefficient: 0.9997\n",
      "getting last token\n",
      "Train Epoch: 37 [0/9 (0%)]\tLoss: 1.117424\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0940\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 38 [0/9 (0%)]\tLoss: 0.624231\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0496\n",
      "Pearson correlation coefficient: 0.9996\n",
      "getting last token\n",
      "Train Epoch: 39 [0/9 (0%)]\tLoss: 0.309942\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0228\n",
      "Pearson correlation coefficient: 0.9993\n",
      "getting last token\n",
      "Train Epoch: 40 [0/9 (0%)]\tLoss: 0.131120\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0087\n",
      "Pearson correlation coefficient: 0.9992\n",
      "getting last token\n",
      "Train Epoch: 41 [0/9 (0%)]\tLoss: 0.047940\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0039\n",
      "Pearson correlation coefficient: 0.9994\n",
      "getting last token\n",
      "Train Epoch: 42 [0/9 (0%)]\tLoss: 0.036362\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0056\n",
      "Pearson correlation coefficient: 0.9997\n",
      "getting last token\n",
      "Train Epoch: 43 [0/9 (0%)]\tLoss: 0.072069\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0112\n",
      "Pearson correlation coefficient: 0.9999\n",
      "getting last token\n",
      "Train Epoch: 44 [0/9 (0%)]\tLoss: 0.128130\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0175\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 45 [0/9 (0%)]\tLoss: 0.178866\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0219\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 46 [0/9 (0%)]\tLoss: 0.198280\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0220\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 47 [0/9 (0%)]\tLoss: 0.172072\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0160\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 48 [0/9 (0%)]\tLoss: 0.085368\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0045\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 49 [0/9 (0%)]\tLoss: 0.000468\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0018\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 50 [0/9 (0%)]\tLoss: 0.117872\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0109\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 51 [0/9 (0%)]\tLoss: 0.062525\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0013\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 52 [0/9 (0%)]\tLoss: 0.007831\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0030\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 53 [0/9 (0%)]\tLoss: 0.039620\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0056\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 54 [0/9 (0%)]\tLoss: 0.043370\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0042\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 55 [0/9 (0%)]\tLoss: 0.021204\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0014\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 56 [0/9 (0%)]\tLoss: 0.003913\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0004\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 57 [0/9 (0%)]\tLoss: 0.010273\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0018\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 58 [0/9 (0%)]\tLoss: 0.026456\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0026\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 59 [0/9 (0%)]\tLoss: 0.019910\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0011\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 60 [0/9 (0%)]\tLoss: 0.004382\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0001\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 61 [0/9 (0%)]\tLoss: 0.001272\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0005\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 62 [0/9 (0%)]\tLoss: 0.008177\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0013\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 63 [0/9 (0%)]\tLoss: 0.012429\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0014\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 64 [0/9 (0%)]\tLoss: 0.009387\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0008\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 65 [0/9 (0%)]\tLoss: 0.003331\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0002\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 66 [0/9 (0%)]\tLoss: 0.000363\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0001\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 67 [0/9 (0%)]\tLoss: 0.002671\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0005\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 68 [0/9 (0%)]\tLoss: 0.006529\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0007\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 69 [0/9 (0%)]\tLoss: 0.006761\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0005\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 70 [0/9 (0%)]\tLoss: 0.003249\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0001\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 71 [0/9 (0%)]\tLoss: 0.000348\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0001\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 72 [0/9 (0%)]\tLoss: 0.001118\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0003\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 73 [0/9 (0%)]\tLoss: 0.003348\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0004\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 74 [0/9 (0%)]\tLoss: 0.003327\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0003\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 75 [0/9 (0%)]\tLoss: 0.001694\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0001\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 76 [0/9 (0%)]\tLoss: 0.000455\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 77 [0/9 (0%)]\tLoss: 0.000540\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0001\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 78 [0/9 (0%)]\tLoss: 0.001616\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0002\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 79 [0/9 (0%)]\tLoss: 0.001981\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0001\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 80 [0/9 (0%)]\tLoss: 0.001254\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0001\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 81 [0/9 (0%)]\tLoss: 0.000356\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 82 [0/9 (0%)]\tLoss: 0.000332\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0001\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 83 [0/9 (0%)]\tLoss: 0.000740\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0001\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 84 [0/9 (0%)]\tLoss: 0.000839\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0001\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 85 [0/9 (0%)]\tLoss: 0.000475\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 86 [0/9 (0%)]\tLoss: 0.000178\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 87 [0/9 (0%)]\tLoss: 0.000225\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 88 [0/9 (0%)]\tLoss: 0.000437\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 89 [0/9 (0%)]\tLoss: 0.000518\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 90 [0/9 (0%)]\tLoss: 0.000306\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 91 [0/9 (0%)]\tLoss: 0.000094\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 92 [0/9 (0%)]\tLoss: 0.000191\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 93 [0/9 (0%)]\tLoss: 0.000278\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 94 [0/9 (0%)]\tLoss: 0.000278\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 95 [0/9 (0%)]\tLoss: 0.000112\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 96 [0/9 (0%)]\tLoss: 0.000022\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 97 [0/9 (0%)]\tLoss: 0.000098\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 98 [0/9 (0%)]\tLoss: 0.000175\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n",
      "getting last token\n",
      "Train Epoch: 99 [0/9 (0%)]\tLoss: 0.000179\n",
      "getting last token\n",
      "\n",
      "Test set: Average loss: 0.0000\n",
      "Pearson correlation coefficient: 1.0000\n"
     ]
    }
   ],
   "source": [
    "run_train(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
